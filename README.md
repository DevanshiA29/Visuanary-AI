# ğŸ‘ï¸ Visionary.AI â€“ See More Than Meets the Eye

[![License](https://img.shields.io/badge/license-MIT-blue.svg)](#license)
[![Built with React](https://img.shields.io/badge/built%20with-React-blue)](#tech-stack)
[![Hosted on Azure](https://img.shields.io/badge/hosted%20on-Azure-blueviolet)](#deployment)
[![Gemini API](https://img.shields.io/badge/powered%20by-Gemini%20Vision-lightgreen)](#api-integration)

> **Visionary.AI** is a next-gen visual assistant powered by Gemini Vision API. Upload an image, ask questions, and receive deep contextual insights in real-time. From document interpretation to object recognition, **Visionary.AI** helps you see, know, and actâ€”smarter.

---

## ğŸš€ Live Demo

![alt text](ss.png)
ğŸ”— [Click to Try Visionary.AI](#)
ğŸ¥ [Watch Demo Video](#)

---

## ğŸ“¸ Key Features

* ğŸ§  **Multimodal Intelligence**: Understands images and responds to custom queries using Gemini's Vision API.
* ğŸ“„ **Context Extraction**: Summarizes documents, posters, charts, or scenes.
* ğŸ¤ **Voice Input & Output**: Ask questions via mic and get AI answers in speech.
* ğŸ–¼ï¸ **Smart Upload UI**: Drag and drop images, annotate, or use webcam.
* ğŸ§¾ **Response Types**: Summaries, bullet points, key details, and follow-ups.
* ğŸŒ™ **Dark Mode & Theming**: Switch between light/dark gradients dynamically.
* ğŸ•“ **History Log**: See past queries and revisit old results (local cache).
* âš¡ **Responsive & Mobile-Ready**: Works seamlessly across devices.

---

## ğŸ› ï¸ Tech Stack

| Layer          | Tools                                            |
| -------------- | ------------------------------------------------ |
| **Frontend**   | React.js, Tailwind CSS, Redux Toolkit            |
| **AI APIs**    | Gemini Vision (Google AI Studio), Web Speech API |
| **Animations** | Framer Motion, Lottie                            |
| **Deployment** | Azure Static Web Apps / Firebase Hosting         |
| **Voice**      | Web Speech (Speech-to-Text + TTS)                |
| **State**      | Redux or Recoil                                  |

---

## ğŸ“‚ Project Structure

```
/src
  /components
    - UploadImage.jsx
    - OutputPanel.jsx
    - VoiceInput.jsx
    - Loader.jsx
  /api
    - gemini.js
  /redux
    - store.js
  /utils
    - promptBuilder.js
App.jsx
index.js
```

---

## ğŸ§ª How It Works

1. ğŸ“„ User uploads an image or uses webcam input
2. âœï¸ Optional: User types a query (e.g. â€œWhatâ€™s in this prescription image?â€)
3. âš™ï¸ Frontend builds prompt and sends to Gemini Vision API
4. ğŸ§  Gemini returns contextual result â†’ displayed in animated output panel
5. ğŸ”€ User can ask follow-up or switch to voice interaction

---

## ğŸ” API Integration

```js
// Example API call
const response = await geminiVision.generate({
  image: uploadedImage,
  prompt: "Summarize the content of this image",
});
```

> *Use environment variable `.env` for API key*
> `VITE_GEMINI_API_KEY=your_key_here`

---

## âœ¨ Screenshots

| Upload Image                           | Gemini Response                            |
| -------------------------------------- | ------------------------------------------ |
| ![upload](./screenshots/upload-ui.png) | ![response](./screenshots/response-ui.png) |

---

## ğŸ“¦ Installation

```bash
git clone https://github.com/your-username/visionary-ai.git
cd visionary-ai
npm install
npm run dev
```

---

## ğŸ§ Use Cases

* âœï¸ Students analyzing handwritten notes
* ğŸ§¾ Professionals summarizing documents/posters
* ğŸ‘ƒ Accessibility for visually impaired (speech response)
* ğŸ­ Image-based product search & insight

---

## ğŸ¤© Future Enhancements

* ğŸ” OCR overlay highlights on image
* ğŸŒ Multilingual voice translation
* ğŸ§  Model comparison (Gemini vs GPT-4 Vision)
* ğŸ§¾ Export response to PDF/Notion

---

## ğŸ™Œ Contributors

* ğŸ’¡ [Devanshi Awasthi](https://github.com/DevanshiA29) â€“ Project Lead, Frontend Dev, AI Integrator

Want to contribute? Feel free to fork, star, and PR! â­

---

## ğŸ“œ License

MIT License Â© 2025 Devanshi Awasthi

---

## ğŸ“¢ Feedback

If you like this project, leave a â­ on GitHub!
For feature requests or bugs, [open an issue](#)!
